<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Dr. Antonino Calapai – Software Engineer & Neuroscientist</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta
    name="description"
    content="Dr. Antonino Calapai – Software Engineer & Neuroscientist building full-stack systems for autonomous data collection, behavioural monitoring, and machine learning."
  />
  <link rel="stylesheet" href="styles.css" />
</head>
<script>
function initCarousel(id) {
  const carousel = document.getElementById(id);
  const track = carousel.querySelector('.carousel-images');
  const images = track.querySelectorAll('img');
  let index = 0;

  const update = () => {
    track.style.transform = `translateX(-${index * 100}%)`;
  };

  carousel.querySelector('.prev').onclick = () => {
    index = (index - 1 + images.length) % images.length;
    update();
  };

  carousel.querySelector('.next').onclick = () => {
    index = (index + 1) % images.length;
    update();
  };
}
</script>
<body>
  <header class="site-header">
    <div class="container header-inner">
      <div class="logo">
        <span class="logo-mark"></span>
        <span class="logo-text">Antonino Calapai</span>
      </div>
      <nav class="nav">
        <a href="#about">About</a>
        <a href="#skills">Skills</a>
        <a href="#experience">Experience</a>
        <a href="#projects">Projects</a>
        <a href="#publications">Publications</a>
        <a href="#contact">Contact</a>
      </nav>
    </div>
  </header>

  <main>
    <!-- Hero -->
    <section id="hero" class="hero">
      <div class="container hero-inner">
        <div class="hero-text">
          <p class="hero-kicker">Software Engineer & Neuroscientist</p>
          <h1>Building autonomous systems for data science and machine learning.</h1>
          <p class="hero-subtitle">
            I specialize in data interfaces, software pipelines, scientific programming, and hardware development.
            I have over a decade of experience building full-stack autonomous devices, systems, and pipelines.
          </p>
          <div class="hero-actions">
            <!-- Update the CV link once your PDF is in the repo -->
            <a class="btn btn-primary" href="#experience">View Experience</a>
            <a class="btn btn-secondary" href="#contact">Contact me</a>
          </div>
        </div>
        <div class="hero-meta">
          <div class="meta-card">
            <p class="meta-label">Location</p>
            <p class="meta-value">Göttingen, Germany (Freiburg from 2026)</p>
          </div>
          <div class="meta-card">
            <p class="meta-label">Current role</p>
            <p class="meta-value">Lead Software Engineer · German Primate Center</p>
          </div>
          <div class="meta-card">
            <p class="meta-label">Focus</p>
            <p class="meta-value">Data engineering · Software Development · Machine vision · Cognitive enrichment</p>
          </div>
        </div>
      </div>
    </section>

    <!-- About -->
    <section id="about" class="section">
      <div class="container section-inner">
        <div class="section-header">
          <h2>About</h2>
<!--          <p class="section-lead">-->
<!--            I am a neuroscientist turned software engineer, building autonomous systems for-->
<!--            studying cognition and behaviour in primates and humans.-->
<!--          </p>-->
        </div>
        <div class="two-column">
          <div>
            <p>
              I was born in Sicily and trained as a neuroscientist and neuropsychologist across Italy, UK, and Germany.
              Over the last decade I have worked at the intersection of cognitive neuroscience, machine vision, and
              software engineering, focusing on advancing knowledge and research methods, efficiently and ethically.
            </p>
            <p>
              During my PhD in Systems Neuroscience at the University of Göttingen, I worked on the electrophysiology
              of the macaque visual cortex and on the psychophysics of spatial attention. Throughout my PostDocs
              I built autonomous systems to turn cognitive training of non-human primates into gamified assessment and enrichment
              that allowed more efficient high-throughput research while enhancing ethical standards.
            </p>
          </div>
          <div>
            <p>
              Today I lead the development of autonomous behavioral tracking and enrichment platforms at the
              Primate Cognition and Behavior facility at the German Primate Center.
            </p>
            <p>
              I enjoy designing systems end-to-end: from CAD models and embedded hardware to data pipelines and user-facing tools for scientists, vets, and technicians.
              My work has led to open-access publications, new research infrastructure, and concrete improvements in animal welfare.
            </p>
            <p>
              Outside of work I am a father of three, an amateur musician, and an aspiring game designer.
            </p>
          </div>
        </div>
      </div>
    </section>

    <!-- Skills -->
    <section id="skills" class="section section-alt">
      <div class="container section-inner">
        <div class="section-header">
          <h2> Full-stack developer</h2>
          <p class="section-lead">
            from embedded linux to front-end interfaces - for data science, machine vision, and advanced UX.
          </p>
        </div>
        <div class="grid skills-grid">
          <div class="card">
            <h3>Programming</h3>
            <ul>
              <li>Python</li>
              <li>Matlab</li>
              <li>C# / C++</li>
              <li>Bash</li>
            </ul>
          </div>
          <div class="card">
            <h3>Machine Vision</h3>
            <ul>
              <li>CUDA / MPS</li>
              <li>OpenCV</li>
              <li>TensorFlow</li>
              <li>CNNs, Poses, Identities</li>
              <li>Markerless 3D tracking</li>
            </ul>
          </div>
          <div class="card">
            <h3>Data</h3>
            <ul>
              <li>End-to-end workflows</li>
              <li>GitHub / CI/CD</li>
              <li>Docker & Ansible</li>
              <li>GPU clusters</li>
            </ul>
          </div>
          <div class="card">
            <h3>Hardware</h3>
            <ul>
              <li>Nvidia Jetson</li>
              <li>Raspberry Pi</li>
              <li>PCB basics</li>
              <li>Microcontrollers</li>
              <li>CAD & 3D printing</li>
              <li>Touchscreens</li>

            </ul>
          </div>
        </div>
      </div>
    </section>

    <!-- Projects -->
    <section id="projects" class="section section-alt">
      <div class="container section-inner">

        <div class="section-header">
          <h2>Portfolio</h2>
          <p class="section-lead">
            A selection of projects at the intersection of neuroscience, machine vision, and autonomous systems.
          </p>
        </div>

        <div class="grid projects-grid">

          <!-- ABT -->
          <article class="card">
            <h3>Autonomous Behavioural Tracking (ABT)</h3>

            <div id="carousel-abt" class="carousel">
              <div class="carousel-images">
                <img src="assets/abt_1.jpg" alt="ABT image 1">
                <img src="assets/abt_2.jpg" alt="ABT image 2">
                <img src="assets/abt_3.jpg" alt="ABT image 3">
              </div>
              <button class="carousel-button prev">‹</button>
              <button class="carousel-button next">›</button>
            </div>

            <p class="project-description">
              In this projects I am lead developer and coordinator of a group engineers and data scientists belonging
              to different research groups of the Cognitive Neuroscience Laboratory (CNL) of the German Primate Center.

              Here I designed and led the development of a stand-alone software to be able to track, identify,
              and extract the posture, of rhesus macaques in their enclosure with the aim of autonomously assessing
              animals’ welfare and behaviour 24/7 without direct interference.
            </p>

            <script>initCarousel("carousel-abt")</script>
          </article>


          <!-- XBI -->
          <article class="card">
            <h3>Touchscreens for Monkeys (XBI)</h3>

            <div id="carousel-xbi" class="carousel">
              <div class="carousel-images">
                <img src="assets/xbi_1.jpg" alt="XBI image 1">
                <img src="assets/xbi_2.jpg" alt="XBI image 2">
                <img src="assets/xbi_3.jpg" alt="XBI image 3">
              </div>
              <button class="carousel-button prev">‹</button>
              <button class="carousel-button next">›</button>
            </div>

            <p class="project-description">
              Designed and deployed touchscreen-based Experimental Behavioral Instruments that
              allow monkeys to train, perform psychophysics, and receive cognitive enrichment
              directly from their home enclosure, significantly reducing stress and scaling
              data collection.
            </p>

            <script>initCarousel("carousel-xbi")</script>
          </article>


          <!-- Machine Vision -->
          <article class="card">
            <h3>Machine Vision for Monkeys</h3>

            <div id="carousel-vision" class="carousel">
              <div class="carousel-images">
                <img src="assets/vision_1.jpg" alt="Machine vision image 1">
                <img src="assets/vision_2.jpg" alt="Machine vision image 2">
                <img src="assets/vision_3.jpg" alt="Machine vision image 3">
              </div>
              <button class="carousel-button prev">‹</button>
              <button class="carousel-button next">›</button>
            </div>

            <p class="project-description">
              Developed CNNs for real-time individual identification, gaze tracking, and behaviour
              extraction from video to support standardised yet individualised training and
              enrichment protocols deployed across multiple facilities.
            </p>

            <script>initCarousel("carousel-vision")</script>
          </article>


          <!-- Gamified Psychophysics -->
          <article class="card">
            <h3>Gamified Psychophysics</h3>

            <div id="carousel-psycho" class="carousel">
              <div class="carousel-images">
                <img src="assets/psycho_1.jpg" alt="Gamified psychophysics image 1">
                <img src="assets/psycho_2.jpg" alt="Gamified psychophysics image 2">
                <img src="assets/psycho_3.jpg" alt="Gamified psychophysics image 3">
              </div>
              <button class="carousel-button prev">‹</button>
              <button class="carousel-button next">›</button>
            </div>

            <p class="project-description">
              Created game-like experimental paradigms in 2D and 3D (e.g., joystick-based tasks in
              Unreal Engine) to study motion processing, social information integration, and
              cognitive flexibility in humans and non-human primates.
            </p>

            <script>initCarousel("carousel-psycho")</script>
          </article>

        </div>
      </div>
    </section>

    <!-- Experience -->
    <section id="experience" class="section">
      <div class="container section-inner">
        <div class="section-header">
          <h2>Experience</h2>
          <p class="section-lead">
            Leading technical teams and infrastructures for animal cognition and machine vision.
          </p>
        </div>
        <div class="timeline">
          <article class="timeline-item">
            <div class="timeline-meta">
              <span class="timeline-role">Lead Machine Vision Engineer</span>
              <span class="timeline-time">2023 – present</span>
            </div>
            <h3>German Primate Center · Göttingen, Germany</h3>
            <p>
              Leading a team of engineers to build full-stack machine vision pipelines for
              <strong>3D tracking and ID recognition of macaques</strong> in a new research
              facility. Responsibilities span system architecture, GPU cluster orchestration,
              and user-facing tools for researchers and animal care staff.
            </p>
          </article>

          <article class="timeline-item">
            <div class="timeline-meta">
              <span class="timeline-role">Postdoctoral Researcher</span>
              <span class="timeline-time">2020 – 2022</span>
            </div>
            <h3>Cognitive Neuroscience Laboratory · German Primate Center</h3>
            <p>
              Developed CNN-based detection systems for autonomous training and assessment of
              monkeys, and designed gamified tasks to increase engagement and data throughput.
              Integrated behavioural, neural, and eye-movement data into unified analysis workflows.
            </p>
          </article>

          <article class="timeline-item">
            <div class="timeline-meta">
              <span class="timeline-role">Junior Postdoctoral Researcher</span>
              <span class="timeline-time">2016 – 2019</span>
            </div>
            <h3>Institute for Auditory Neuroscience · University Medical Center Göttingen</h3>
            <p>
              Built autonomous auditory training and psychophysics systems for common marmosets
              and implemented group-based cognitive training and enrichment protocols for macaques.
            </p>
          </article>

          <article class="timeline-item">
            <div class="timeline-meta">
              <span class="timeline-role">PhD in Systems Neuroscience</span>
              <span class="timeline-time">2011 – 2016</span>
            </div>
            <h3>University of Göttingen · Germany</h3>
            <p>
              Worked on multidimensional mapping of macaque visual cortex (area MST), eye movements
              and visual attention in humans, and early prototypes of cage-based autonomous
              touchscreens for monkeys.
            </p>
          </article>
        </div>
      </div>
    </section>

    <!-- Publications -->
    <section id="publications" class="section">
      <div class="container section-inner">
        <div class="section-header">
          <h2>Selected Publications</h2>
          <p class="section-lead">
            A subset of peer-reviewed work spanning methods, cognition, and animal enrichment.
          </p>
        </div>
        <ul class="pub-list">
          <li>
            <strong>Calapai A. et al. (2022)</strong> –
            Flexible auditory training, psychophysics, and enrichment of common marmosets with an
            automated, touchscreen-based system. <em>Nature Communications</em>.
          </li>
          <li>
            <strong>Calapai A. et al. (2016)</strong> –
            A cage-based training, cognitive testing and enrichment system for rhesus macaques.
            <em>Behavior Research Methods</em>.
          </li>
          <li>
            <strong>Berger M., Calapai A. et al. (2018)</strong> –
            Standardized automated training of rhesus monkeys in their housing environment.
            <em>Journal of Neurophysiology</em>.
          </li>
          <li>
            <strong>Xue C., Calapai A. et al. (2020)</strong> –
            Sustained spatial attention accounts for the direction bias of human microsaccades.
            <em>Scientific Reports</em>.
          </li>
          <li>
            <strong>Cabrera-Moreno J., Calapai A. et al. (2022)</strong> –
            Group-based, autonomous, individualized training and testing of long-tailed macaques
            in their home enclosure. <em>Frontiers in Psychology</em>.
          </li>
          <li>
            Full list available on request.
          </li>
        </ul>
      </div>
    </section>

    <!-- Contact -->
    <section id="contact" class="section section-alt">
      <div class="container section-inner">
        <div class="section-header">
          <h2>Contact</h2>
          <p class="section-lead">
            Open to roles in data engineering, software engineering, and applied machine vision,
            preferably with strong remote flexibility.
          </p>
        </div>
        <div class="contact-grid">
          <div>
            <h3>Get in touch</h3>
            <p>
              For collaborations, opportunities, or questions about my work, feel free to reach out.
            </p>
            <ul class="contact-list">
              <li><strong>Email:</strong> <a href="mailto:antonio.calapai@gmail.com">antonio.calapai@gmail.com</a></li>
              <li><strong>LinkedIn:</strong> <a href="https://www.linkedin.com/in/antonino-calapai-6b8338266" target="_blank" rel="noopener">linkedin.com/in/antonino-calapai-6b8338266</a></li>
              <li><strong>GitHub:</strong> <a href="https://github.com/antoniocalapai" target="_blank" rel="noopener">github.com/antoniocalapai</a></li>
              <li><strong>Location:</strong> Göttingen → Freiburg (Germany)</li>
            </ul>
          </div>
          <div>
            <h3>Current interests</h3>
            <ul class="pill-list">
              <li>Data & ML engineering roles</li>
              <li>Machine vision & tracking</li>
              <li>Cognitive enrichment platforms</li>
              <li>Robotics & interactive systems</li>
            </ul>
          </div>
        </div>
      </div>
    </section>
  </main>

  <footer class="site-footer">
    <div class="container footer-inner">
      <p>© <span id="year"></span> Antonino Calapai</p>
      <p>Built with plain HTML &amp; CSS · Hosted on GitHub Pages</p>
    </div>
    <script>
      // Simple year update, no dependencies
      document.getElementById('year').textContent = new Date().getFullYear();
    </script>
  </footer>
</body>
</html>