<article id="project-dyadic" class="card project-panel active">
  <h3>Dyadic Continuous Perceptual Decision-Making</h3>

  <div id="carousel-dyadic" class="carousel">
    <div class="carousel-images">
      <img src="assets/cpr_1.jpg" alt="Dyadic CPR Task">
      <img src="assets/cpr_2.jpg" alt="Dyadic CPR Example">
    </div>
    <button class="carousel-button prev">‹</button>
    <button class="carousel-button next">›</button>
  </div>

  <p class="project-description" style="margin-bottom:1.6rem;">
    This project investigates how humans integrate <strong>real-time social perceptual signals</strong>
    during continuous decision-making. Inspired by classical random-dot motion paradigms, it extends
    them into a <strong>dynamic, joystick-based “Continuous Perceptual Report” (CPR)</strong> task that
    allows moment-to-moment tracking of perceived motion direction and confidence.
  </p>

  <p class="project-description" style="margin-bottom:1.6rem;">
    Two participants see the same noisy motion stimulus and simultaneously report their perceived
    direction using joysticks. Tilt amplitude encodes <strong>confidence</strong>, providing a continuous
    readout of both perceptual estimates and internal certainty. Crucially, each player also sees the
    partner’s current estimate in real time, creating a <strong>dyadic perceptual interaction</strong>.
  </p>

  <h4 style="margin-top:1.4rem;">Core Scientific Question</h4>
  <p class="project-description" style="margin-bottom:1.6rem;">
    Does a person integrate another observer’s real-time perceptual judgment—even when collaboration is
    <em>not</em> required and payoffs are <em>independent</em>?
  </p>

  <h4 style="margin-top:1.4rem;">Key Findings</h4>

  <ul style="margin-left:1.2rem; margin-bottom:1.2rem; color:var(--fg-muted);">
    <li><strong>Mutual convergence:</strong> partners tend to influence each other’s continuous estimates.</li>
    <li><strong>Asymmetric effects:</strong> less accurate partners improve in accuracy and confidence.</li>
    <li><strong>Cost to the better partner:</strong> more accurate participants lose precision but keep higher confidence.</li>
    <li><strong>Group-level consequence:</strong> dyads become <strong>more confident</strong> without becoming uniformly more accurate.</li>
    <li><strong>Control experiments:</strong> humans integrate directional information even when confidence cues from the partner are unreliable.</li>
  </ul>

  <p class="project-description" style="margin-bottom:1.6rem;">
    These results show that <strong>social information is integrated continuously and opportunistically</strong>
    during perceptual decision-making, revealing lawful interactions between accuracy, confidence, and
    partner reliability.
  </p>

  <h4 style="margin-top:1.4rem;">Publication</h4>
  <p class="project-description">
    Confidence over competence: real-time integration of social information in human continuous perceptual decision-making.
    F. Schneider, A. Calapai, R. Mundry, R. Báez-Mendoza, A. Gail, I. Kagan, S. Treue (2024)
    <a href="https://elifesciences.org/reviewed-preprints/101021"
       target="_blank" rel="noopener"
       style="color:#ffd44b;">eLife </a>
  </p>

  <script>initCarousel("carousel-dyadic")</script>
</article>